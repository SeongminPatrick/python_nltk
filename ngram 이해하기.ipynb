{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation discovery     \n",
    "\n",
    "    nltk.collocations             t-test, chi-squared, point-wise mutual information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbstractCollocationFinder',\n",
       " 'BigramAssocMeasures',\n",
       " 'BigramCollocationFinder',\n",
       " 'ContingencyMeasures',\n",
       " 'FreqDist',\n",
       " 'QuadgramCollocationFinder',\n",
       " 'TrigramAssocMeasures',\n",
       " 'TrigramCollocationFinder',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_itertools',\n",
       " 'demo',\n",
       " 'iteritems',\n",
       " 'ngrams',\n",
       " 'print_function',\n",
       " 'ranks_from_scores',\n",
       " 'spearman_correlation']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.collocations\n",
    "\n",
    "dir(nltk.collocations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function nltk.util.ngrams>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.collocations.ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 65536)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.collocations.print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt\n",
      "\t ['download manager', 'http ://', 'new tab', 'context menu', 'address bar', 'print preview', 'location bar', 'mozilla firebird', 'bookmarks toolbar', 'password manager', 'new window', 'status bar', 'full screen', 'dom inspector', 'personal toolbar']\n",
      "\t Correlation to raw_freq: 0.6075\n",
      "grail.txt\n",
      "\t ['black knight', 'clop clop', 'head knight', 'mumble mumble', 'squeak squeak', 'saw saw', 'holy grail', 'run away', 'french guard', 'cartoon character', 'iesu domine', 'pie iesu', 'round table', 'sir robin', 'clap clap']\n",
      "\t Correlation to raw_freq: 0.7946\n",
      "overheard.txt\n",
      "\t ['teen girl', 'new york', 'teen boy', 'little boy', 'little girl', 'last night', 'old lady', 'old man', 'bus driver', 'long island', 'high school', 'drunk guy', 'look like', 'hipster girl', 'flight attendant']\n",
      "\t Correlation to raw_freq: 0.5209\n",
      "pirates.txt\n",
      "\t ['jack sparrow', 'elizabeth swann', 'davy jones', 'flying dutchman', 'lord cutler', 'cutler beckett', 'black pearl', 'tia dalma', 'cannibal island', 'port royal', 'bamboo pole', 'edinburgh trader', 'east india', 'india trading', 'wounded sailor']\n",
      "\t Correlation to raw_freq: 0.6932\n",
      "singles.txt\n",
      "\t ['would like', 'age open', 'medium build', 'social drinker', 'non smoker', 'quiet nights', 'long term', 'easy going', 'poss rship', 'financially secure', 'fun times', 'weekends away', 'seeks lady', 'single dad', 'similar interests']\n",
      "\t Correlation to raw_freq: 0.6389\n",
      "wine.txt\n",
      "\t ['top ***', 'bare ****', 'bare ***', 'good length', 'bare ***(*)', 'medium weight', 'needs time', 'pretty good', 'mature claret', 'nice balance', 'red fruits', 'rather good', 'white burgundy', 'quite forward', 'top ****']\n",
      "\t Correlation to raw_freq: 0.5347\n"
     ]
    }
   ],
   "source": [
    "nltk.collocations.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gram 함수로 처리하기..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'How', 'are', 'you', '?', 'i', 'am', 'fine', 'and', 'you']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "\n",
    "text = \"Hi How are you? i am fine and you\"\n",
    "token=nltk.word_tokenize(text)\n",
    "\n",
    "print(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hi', 'How'), ('How', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'fine'), ('fine', 'and'), ('and', 'you')]\n",
      "[('Hi', 'How', 'are'), ('How', 'are', 'you'), ('are', 'you', '?'), ('you', '?', 'i'), ('?', 'i', 'am'), ('i', 'am', 'fine'), ('am', 'fine', 'and'), ('fine', 'and', 'you')]\n"
     ]
    }
   ],
   "source": [
    "print(list(bigrams(token)))\n",
    "print(list(trigrams(token)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ngrams 함수 알아보기\n",
    "\n",
    "\n",
    "nltk.util.ngrams (순서, n, pad_left = 거짓, pad_right = 거짓, pad_symbol = 없음).\n",
    "\n",
    "\n",
    "\n",
    "    sequence - ngrams (순차 순서 또는 iter)로 변환되는 소스 데이터\n",
    "\n",
    "    n - ngrams (int)의 차수\n",
    "\n",
    "    pad_left - ngram을 왼쪽으로 채워야하는지 (bool)\n",
    "\n",
    "    pad_right - ngram이 오른쪽으로 채워 져야하는지 (bool)\n",
    "    \n",
    "    right_pad_symbol, left_pad_symbol - 패딩에 사용할 기호입니다 (기본값은 None, any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2, 3), (2, 3, 4), (3, 4, 5)]\n",
      "[(1, 2), (2, 3), (3, 4), (4, 5), (5, None)]\n",
      "[(1, 2), (2, 3), (3, 4), (4, 5), (5, 'END')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "print(list(ngrams([1,2,3,4,5], 3)))\n",
    "print(list(ngrams([1,2,3,4,5], 2, pad_right=True)))\n",
    "print(list(ngrams([1,2,3,4,5], 2, pad_right=True,right_pad_symbol=\"END\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ngram으로 문장을 분리하기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'How', 'are', 'you', '?', 'i', 'am', 'fine', 'and', 'you']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "text = \"Hi How are you? i am fine and you\"\n",
    "token=nltk.word_tokenize(text)\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object ngrams at 0x11080da40>\n",
      "[('Hi',), ('How',), ('are',), ('you',), ('?',), ('i',), ('am',), ('fine',), ('and',), ('you',)]\n"
     ]
    }
   ],
   "source": [
    "unigrams=ngrams(token,1)\n",
    "\n",
    "print(unigrams)\n",
    "\n",
    "print(list(unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object ngrams at 0x11aaaf3b8>\n",
      "[('Hi', 'How'), ('How', 'are'), ('are', 'you'), ('you', '?'), ('?', 'i'), ('i', 'am'), ('am', 'fine'), ('fine', 'and'), ('and', 'you')]\n"
     ]
    }
   ],
   "source": [
    "bigrams=ngrams(token,2)\n",
    "\n",
    "print(bigrams)\n",
    "\n",
    "print(list(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object ngrams at 0x11aaaf0f8>\n",
      "[('Hi', 'How', 'are'), ('How', 'are', 'you'), ('are', 'you', '?'), ('you', '?', 'i'), ('?', 'i', 'am'), ('i', 'am', 'fine'), ('am', 'fine', 'and'), ('fine', 'and', 'you')]\n"
     ]
    }
   ],
   "source": [
    "trigrams=ngrams(token,3)\n",
    "\n",
    "print(trigrams)\n",
    "\n",
    "print(list(trigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genesis corpus 사용해서 알아보기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PlaintextCorpusReader in '/Users/dahlmoon/nltk_data/corpora/genesis'>\n",
      "['english-kjv.txt', 'english-web.txt', 'finnish.txt', 'french.txt', 'german.txt', 'lolcat.txt', 'portuguese.txt', 'swedish.txt']\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "\n",
    "print(nltk.corpus.genesis)\n",
    "\n",
    "print(nltk.corpus.genesis.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['In', 'the', 'beginning', 'God', 'created', 'the', 'heavens', 'and', 'the', 'earth', '.'], ['Now', 'the', 'earth', 'was', 'formless', 'and', 'empty', '.'], ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.genesis.sents('english-web.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In', 'the', 'beginning', 'God', 'created', 'the', ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.genesis.words('english-web.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44054\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(nltk.corpus.genesis.words('english-web.txt'))\n",
    "\n",
    "print(finder.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Allon', 'Bacuth'),\n",
       " ('Ashteroth', 'Karnaim'),\n",
       " ('Ben', 'Ammi'),\n",
       " ('En', 'Mishpat'),\n",
       " ('Jegar', 'Sahadutha'),\n",
       " ('Salt', 'Sea'),\n",
       " ('Whoever', 'sheds'),\n",
       " ('appoint', 'overseers'),\n",
       " ('aromatic', 'resin'),\n",
       " ('cutting', 'instrument')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(bigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
