{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.050197203298673"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16.050197203298673"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3) / len(set(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corpus 모듈 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc alpino brown cess_cat cess_esp cmudict comparative_sentences comtrans conll2000 conll2002 conll2007 crubadan demo dependency_treebank find_corpus_fileids floresta framenet framenet15 gazetteers genesis gutenberg ieer inaugural indian jeita knbc lin_thesaurus mac_morpho machado masc_tagged movie_reviews multext_east names nombank nombank_ptb nonbreaking_prefixes nps_chat opinion_lexicon perluniprops ppattach product_reviews_1 product_reviews_2 propbank propbank_ptb pros_cons ptb qc re reader reuters rte semcor senseval sentence_polarity sentiwordnet shakespeare sinica_treebank state_union stopwords subjectivity swadesh swadesh110 swadesh207 switchboard tagged_treebank_para_block_reader teardown_module timit timit_tagged toolbox treebank treebank_chunk treebank_raw twitter_samples udhr udhr2 universal_treebanks util verbnet webtext wordnet wordnet_ic words "
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for i in dir(nltk.corpus) :\n",
    "    \n",
    "    if re.match('[A-Z]',i[0]) :\n",
    "        continue\n",
    "        \n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PlaintextCorpusReader in '/Users/dahlmoon/nltk_data/corpora/gutenberg'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192427\n"
     ]
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "print(len(emma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192427\n",
      "Displaying 25 of 37 matches:\n",
      "er father , was sometimes taken by surprize at his being still able to pity ` \n",
      "hem do the other any good .\" \" You surprize me ! Emma must do Harriet good : a\n",
      "Knightley actually looked red with surprize and displeasure , as he stood up ,\n",
      "r . Elton , and found to his great surprize , that Mr . Elton was actually on \n",
      "d aid .\" Emma saw Mrs . Weston ' s surprize , and felt that it must be great ,\n",
      "father was quite taken up with the surprize of so sudden a journey , and his f\n",
      "y , in all the favouring warmth of surprize and conjecture . She was , moreove\n",
      "he appeared , to have her share of surprize , introduction , and pleasure . Th\n",
      "ir plans ; and it was an agreeable surprize to her , therefore , to perceive t\n",
      "talking aunt had taken me quite by surprize , it must have been the death of m\n",
      "f all the dialogue which ensued of surprize , and inquiry , and congratulation\n",
      " the present . They might chuse to surprize her .\" Mrs . Cole had many to agre\n",
      "the mode of it , the mystery , the surprize , is more like a young woman ' s s\n",
      " to her song took her agreeably by surprize -- a second , slightly but correct\n",
      "\" \" Oh ! no -- there is nothing to surprize one at all .-- A pretty fortune ; \n",
      "t to be considered . Emma ' s only surprize was that Jane Fairfax should accep\n",
      "of your admiration may take you by surprize some day or other .\" Mr . Knightle\n",
      "ation for her will ever take me by surprize .-- I never had a thought of her i\n",
      " expected by the best judges , for surprize -- but there was great joy . Mr . \n",
      " sound of at first , without great surprize . \" So unreasonably early !\" she w\n",
      "d Frank Churchill , with a look of surprize and displeasure .-- \" That is easy\n",
      "; and Emma could imagine with what surprize and mortification she must be retu\n",
      "tled that Jane should go . Quite a surprize to me ! I had not the least idea !\n",
      " . It is impossible to express our surprize . He came to speak to his father o\n",
      "g engaged !\" Emma even jumped with surprize ;-- and , horror - struck , exclai\n"
     ]
    }
   ],
   "source": [
    "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
    "print(len(emma))\n",
    "emma.concordance('surprize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for문 해석\n",
    "    num_chars: 모든 문자\n",
    "    num_words: 모든 단어\n",
    "    num_sents: 모든 문장이나 말투??\n",
    "    num_vocab: 모든 단어들 중에서 유일한 단어\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887071 192427 7752 7344 austen-emma.txt\n",
      "466292 98171 3747 5835 austen-persuasion.txt\n",
      "673022 141576 4999 6403 austen-sense.txt\n",
      "4332554 1010654 30103 12767 bible-kjv.txt\n",
      "38153 8354 438 1535 blake-poems.txt\n",
      "249439 55563 2863 3940 bryant-stories.txt\n",
      "84663 18963 1054 1559 burgess-busterbrown.txt\n",
      "144395 34110 1703 2636 carroll-alice.txt\n",
      "457450 96996 4779 8335 chesterton-ball.txt\n",
      "406629 86063 3806 7794 chesterton-brown.txt\n",
      "320525 69213 3742 6349 chesterton-thursday.txt\n",
      "935158 210663 10230 8447 edgeworth-parents.txt\n",
      "1242990 260819 10059 17231 melville-moby_dick.txt\n",
      "468220 96825 1851 9021 milton-paradise.txt\n",
      "112310 25833 2163 3032 shakespeare-caesar.txt\n",
      "162881 37360 3106 4716 shakespeare-hamlet.txt\n",
      "100351 23140 1907 3464 shakespeare-macbeth.txt\n",
      "711215 154883 4250 12452 whitman-leaves.txt\n"
     ]
    }
   ],
   "source": [
    "for fileid in nltk.corpus.gutenberg.fileids():\n",
    "    num_chars = len(nltk.corpus.gutenberg.raw(fileid))\n",
    "    num_words = len(nltk.corpus.gutenberg.words(fileid))\n",
    "    num_sents = len(nltk.corpus.gutenberg.sents(fileid))\n",
    "    num_vocab = len(set([w.lower() for w in nltk.corpus.gutenberg.words(fileid)]))\n",
    "    print(int(num_chars), int(num_words),int(num_sents),int(num_vocab), fileid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문자를 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Poems by '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.raw('blake-poems.txt')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어를 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Poems',\n",
       " 'by',\n",
       " 'William',\n",
       " 'Blake',\n",
       " '1789',\n",
       " ']',\n",
       " 'SONGS',\n",
       " 'OF',\n",
       " 'INNOCENCE']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.words('blake-poems.txt')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장을 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'Poems', 'by', 'William', 'Blake', '1789', ']'],\n",
      " ['SONGS',\n",
      "  'OF',\n",
      "  'INNOCENCE',\n",
      "  'AND',\n",
      "  'OF',\n",
      "  'EXPERIENCE',\n",
      "  'and',\n",
      "  'THE',\n",
      "  'BOOK',\n",
      "  'of',\n",
      "  'THEL'],\n",
      " ['SONGS', 'OF', 'INNOCENCE']]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(nltk.corpus.gutenberg.sents('blake-poems.txt')[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복된 단어를 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1535"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vocab2 = len(set([w.lower() for w in nltk.corpus.gutenberg.words('blake-poems.txt')]))\n",
    "num_vocab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agree', 'sighs', 'friend', 'hither', 'unrest', 'morn', 'going', 'horn', 'babe', 'fears']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set([w.lower() for w in nltk.corpus.gutenberg.words('blake-poems.txt')]))\n",
    "\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firefox.txt',\n",
       " 'grail.txt',\n",
       " 'overheard.txt',\n",
       " 'pirates.txt',\n",
       " 'singles.txt',\n",
       " 'wine.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpora'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps_chat.subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chatroom = nps_chat.posts('10-19-20s_706posts.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'hot',\n",
       " 'pics',\n",
       " 'of',\n",
       " 'a',\n",
       " 'female',\n",
       " ',',\n",
       " 'I',\n",
       " 'can',\n",
       " 'look',\n",
       " 'in',\n",
       " 'a',\n",
       " 'mirror',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatroom[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "1176896\n",
      "b'The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    "raw = urlopen(url).read()\n",
    "print(type(raw))\n",
    "print(len(raw))  # 책과 다름.\n",
    "print(raw[:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바이트를 문자열로 변환해줘야 함. 3버전 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "254352\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "text1 = str(raw,encoding=\"utf-8\")\n",
    "tokens = nltk.word_tokenize(text1)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['AND', 'PUNISHMENT', 'PART', 'I', 'CHAPTER', 'I', 'On', 'an', 'exceptionally', 'hot', 'evening', 'early', 'in', 'July', 'a', 'young', 'man', 'came', 'out', 'of', 'the', 'garret', 'in', 'which', 'he', 'lodged', 'in', 'S.', 'Place', 'and', 'walked', 'slowly', ',', 'as', 'though', 'in', 'hesitation', ',', 'towards', 'K.']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; Nikodim Fomitch; young man; Ilya Petrovitch; n't know;\n",
      "Project Gutenberg; Dmitri Prokofitch; Andrey Semyonovitch; Hay Market\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[1020:1060])  \n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5338\n",
      "1157746\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(text1.find(\"PART I\"))\n",
    "print(text1.rfind(\"End of Project Gutenberg's Crime\")) # 역으로 검색\n",
    "\n",
    "# 이상을 제거한 부분만 사용해야 한다.\n",
    "\n",
    "raw = text1[5338:1157743] \n",
    "print(raw.find(\"PART I\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
